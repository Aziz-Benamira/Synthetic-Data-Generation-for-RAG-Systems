# Shared Resources

This directory contains utilities, data, and configurations shared across all research tracks.

## ğŸ“ Structure

```
shared/
â”œâ”€â”€ utils/                  # Shared utility functions
â”‚   â”œâ”€â”€ llm/               # LLM client wrappers
â”‚   â”œâ”€â”€ embeddings/        # Embedding utilities
â”‚   â”œâ”€â”€ evaluation/        # Shared evaluation metrics
â”‚   â””â”€â”€ preprocessing/     # Data preprocessing
â”œâ”€â”€ data/                   # Shared datasets
â”‚   â”œâ”€â”€ raw/               # Raw documents (PDFs, etc.)
â”‚   â”œâ”€â”€ processed/         # Processed documents
â”‚   â””â”€â”€ datasets/          # Final generated datasets
â””â”€â”€ configs/                # Shared configurations
    â”œâ”€â”€ models/            # LLM model configs
    â”œâ”€â”€ generation/        # Generation configs
    â””â”€â”€ evaluation/        # Evaluation configs
```

## ğŸ¯ Purpose

- **Avoid Code Duplication** - Write once, use everywhere
- **Consistency** - Same preprocessing, embeddings, API calls
- **Easy Integration** - All tracks use same utilities
- **Version Control** - Single source of truth

## ğŸ› ï¸ Shared Utilities

### LLM Clients (`utils/llm/`)
```python
from shared.utils.llm import OpenAIClient, AnthropicClient

client = OpenAIClient(model="gpt-4-turbo")
response = client.generate(prompt="...", temperature=0.7)
```

### Embeddings (`utils/embeddings/`)
```python
from shared.utils.embeddings import get_embeddings

embeddings = get_embeddings(texts, model="text-embedding-3-large")
```

### Evaluation Metrics (`utils/evaluation/`)
```python
from shared.utils.evaluation import calculate_ragas_metrics

scores = calculate_ragas_metrics(
    questions=questions,
    answers=answers,
    contexts=contexts
)
```

## ğŸ“Š Shared Data

### Raw Documents (`data/raw/`)
- Store original PDFs, documents here
- Accessible to all tracks
- Not tracked in git (too large)

### Processed Data (`data/processed/`)
- Chunked documents
- Extracted metadata
- Vector embeddings

### Final Datasets (`data/datasets/`)
- Generated QA pairs
- Evaluation results
- Benchmark datasets
- **Will be published to HuggingFace**

## âš™ï¸ Shared Configs

### Model Configurations (`configs/models/`)
```yaml
# gpt-4-turbo.yaml
model: gpt-4-turbo
temperature: 0.7
max_tokens: 2000
top_p: 0.95
```

### Generation Configurations (`configs/generation/`)
- Prompt templates
- Generation parameters
- Quality thresholds

## ğŸ¤ Contribution Guidelines

### Adding Utilities
1. Create module in appropriate `utils/` subfolder
2. Add docstrings and type hints
3. Write unit tests
4. Update this README

### Using Shared Resources
```python
# Add shared to path
import sys
sys.path.append('../../shared')

# Import utilities
from utils.llm import OpenAIClient
from utils.evaluation import calculate_metrics
```

## ğŸ“¦ Installation

```bash
# Install shared dependencies
pip install -r ../../requirements.txt

# For development
pip install -e ../../  # Install as editable package
```

## ğŸ“ Best Practices

âœ… **DO:**
- Put reusable code here
- Document all functions
- Write tests
- Use type hints

âŒ **DON'T:**
- Put track-specific code here
- Hardcode paths or API keys
- Commit large data files
- Break existing APIs without notice
