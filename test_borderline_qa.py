"""
Test Critic Agent avec QA BORDERLINE / CAS LIMITES
===================================================

VÃ©rifie que le Critic produit des scores variÃ©s (pas juste 0% ou 100%)
et discrimine les cas subtils.
"""

import sys
import os
from dotenv import load_dotenv

load_dotenv()

sys.path.insert(0, 'src/chunking')
sys.path.insert(0, 'src/agents')

from semantic_chunker import SemanticChunker
from answer_generator import QAPair
from critic_agent import CriticAgent, FinalDecision
import json

api_key = os.getenv("GROQ_API_KEY")
from groq import Groq


def create_borderline_qa_pairs(chunk):
    """
    CrÃ©er des QA pairs BORDERLINE - ni parfaits ni catastrophiques.
    Ces cas doivent produire des scores variÃ©s (0.4-0.8).
    """
    
    borderline_pairs = []
    
    # Le chunk parle de : intersection de tribus, sous-tribus, tribu engendrÃ©e
    # Contenu clÃ©: "Une intersection de tribus est une tribu"
    #              "une rÃ©union de tribus n'est pas une tribu"
    #              "Une sous-tribu de F est une tribu G telle que G âŠ‚ F"
    
    # 1. LÃ‰GÃˆREMENT IMPRÃ‰CIS - RÃ©ponse correcte mais approximative
    borderline_pairs.append({
        "label": "LÃ‰GÃˆREMENT IMPRÃ‰CIS - Bonne idÃ©e, formulation floue",
        "expected_issues": ["completeness ou clarity faible"],
        "qa": QAPair(
            question="Qu'est-ce qu'une sous-tribu ?",
            answer="Une sous-tribu c'est quand on a une tribu qui est contenue dans une autre tribu plus grande.",
            question_type="factual",
            difficulty="easy",
            supporting_quotes=["Une sous-tribu de F est une tribu G telle que G âŠ‚F"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.7
        )
    })
    
    # 2. PARTIELLEMENT ANCRÃ‰ - Citation prÃ©sente mais rÃ©ponse ajoute un peu
    borderline_pairs.append({
        "label": "PARTIELLEMENT ANCRÃ‰ - RÃ©ponse va lÃ©gÃ¨rement au-delÃ ",
        "expected_issues": ["anchoring moyen"],
        "qa": QAPair(
            question="Pourquoi une intersection de tribus est-elle une tribu ?",
            answer="Une intersection de tribus est une tribu car elle hÃ©rite des propriÃ©tÃ©s de fermeture par complÃ©mentation et union dÃ©nombrable de chaque tribu composante. C'est une consÃ©quence directe de la dÃ©finition axiomatique.",
            question_type="conceptual",
            difficulty="medium",
            supporting_quotes=["Une intersection de tribus est une tribu"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.75
        )
    })
    
    # 3. QUESTION LÃ‰GITIME, RÃ‰PONSE TROP COURTE
    borderline_pairs.append({
        "label": "RÃ‰PONSE TROP SUCCINCTE - Correcte mais manque de dÃ©tail",
        "expected_issues": ["completeness faible"],
        "qa": QAPair(
            question="Quelle est la diffÃ©rence entre une intersection et une rÃ©union de tribus ?",
            answer="L'intersection de tribus est une tribu, mais pas la rÃ©union.",
            question_type="comparative",
            difficulty="medium",
            supporting_quotes=[
                "Une intersection de tribus est une tribu",
                "une rÃ©union de tribus n'est pas une tribu"
            ],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.8
        )
    })
    
    # 4. FORMULATION MALADROITE - Correct sur le fond, confus dans la forme
    borderline_pairs.append({
        "label": "FORMULATION CONFUSE - Fond correct, forme maladroite",
        "expected_issues": ["clarity faible"],
        "qa": QAPair(
            question="Comment dÃ©finit-on la plus petite tribu contenant une famille d'ensembles ?",
            answer="Eh bien, pour avoir la plus petite tribu, on prend toutes les tribus qui contiennent cette famille, et puis on fait l'intersection de toutes ces tribus-lÃ , et Ã§a donne la plus petite tribu parce que l'intersection de tribus c'est une tribu.",
            question_type="procedural",
            difficulty="medium",
            supporting_quotes=["La plus petite tribu contenant une famille d'ensembles est l'intersection de toutes les tribus"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.7
        )
    })
    
    # 5. LÃ‰GÃˆRE EXTRAPOLATION - Part du chunk mais extrapole un peu
    borderline_pairs.append({
        "label": "LÃ‰GÃˆRE EXTRAPOLATION - DÃ©duit quelque chose non explicite",
        "expected_issues": ["local_answerability ou anchoring moyen"],
        "qa": QAPair(
            question="Que peut-on dÃ©duire sur les opÃ©rations ensemblistes appliquÃ©es aux tribus ?",
            answer="On peut dÃ©duire que les tribus sont stables par intersection mais pas par rÃ©union. Cela suggÃ¨re que l'intersection prÃ©serve les propriÃ©tÃ©s de fermeture tandis que la rÃ©union peut les dÃ©truire.",
            question_type="causal",
            difficulty="hard",
            supporting_quotes=[
                "Une intersection de tribus est une tribu",
                "une rÃ©union de tribus n'est pas une tribu"
            ],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.65
        )
    })
    
    # 6. CITATION DÃ‰CONTEXTUALISÃ‰E - Utilise une citation hors de son sens
    borderline_pairs.append({
        "label": "CITATION MAL UTILISÃ‰E - Citation correcte, interprÃ©tation douteuse",
        "expected_issues": ["factual_accuracy moyen"],
        "qa": QAPair(
            question="Pourquoi dit-on qu'une sous-tribu est 'plus petite' ?",
            answer="Une sous-tribu G de F est dite plus petite car elle est contenue dans F. Donc tous les Ã©lÃ©ments de G sont aussi dans F, ce qui fait que G a moins d'Ã©lÃ©ments que F en gÃ©nÃ©ral.",
            question_type="conceptual",
            difficulty="easy",
            supporting_quotes=["Une sous-tribu de F est une tribu G telle que G âŠ‚F"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.6
        )
    })
    
    # 7. QUESTION AMBIGUÃ‹ - Peut Ãªtre interprÃ©tÃ©e de plusieurs faÃ§ons
    borderline_pairs.append({
        "label": "QUESTION AMBIGUÃ‹ - InterprÃ©tation discutable",
        "expected_issues": ["local_answerability ou clarity"],
        "qa": QAPair(
            question="Qu'est-ce qui se passe avec les tribus quand on les combine ?",
            answer="Quand on combine des tribus, le rÃ©sultat dÃ©pend de l'opÃ©ration : une intersection donne toujours une tribu, mais une rÃ©union ne donne pas forcÃ©ment une tribu.",
            question_type="conceptual",
            difficulty="easy",
            supporting_quotes=[
                "Une intersection de tribus est une tribu",
                "une rÃ©union de tribus n'est pas une tribu"
            ],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.7
        )
    })
    
    # 8. RÃ‰PONSE VRAIE MAIS TRIVIALE
    borderline_pairs.append({
        "label": "TROP TRIVIAL - RÃ©ponse correcte mais n'apporte rien",
        "expected_issues": ["completeness trÃ¨s faible"],
        "qa": QAPair(
            question="Qu'est-ce qu'une tribu engendrÃ© par une famille d'ensembles ?",
            answer="C'est la plus petite tribu qui contient cette famille.",
            question_type="factual",
            difficulty="easy",
            supporting_quotes=["La plus petite tribu contenant une famille d'ensembles"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.8
        )
    })
    
    # 9. AJOUT D'EXEMPLE NON PRÃ‰SENT
    borderline_pairs.append({
        "label": "EXEMPLE INVENTÃ‰ - Concept correct, exemple non dans le chunk",
        "expected_issues": ["anchoring faible"],
        "qa": QAPair(
            question="Comment fonctionne une intersection de tribus ?",
            answer="Une intersection de tribus est une tribu. Par exemple, si on prend la tribu des borÃ©liens et la tribu de Lebesgue sur R, leur intersection est aussi une tribu.",
            question_type="application",
            difficulty="medium",
            supporting_quotes=["Une intersection de tribus est une tribu"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.6
        )
    })
    
    # 10. TERMINOLOGIE LÃ‰GÃˆREMENT INCORRECTE
    borderline_pairs.append({
        "label": "TERMINOLOGIE APPROXIMATIVE - Sens correct, mots imprÃ©cis",
        "expected_issues": ["factual_accuracy ou clarity"],
        "qa": QAPair(
            question="Qu'est-ce qui caractÃ©rise une sous-tribu ?",
            answer="Une sous-tribu est un sous-ensemble d'une tribu qui garde les mÃªmes propriÃ©tÃ©s de tribu. C'est quand une tribu G est incluse dans une tribu F.",
            question_type="conceptual",
            difficulty="easy",
            supporting_quotes=["Une sous-tribu de F est une tribu G telle que G âŠ‚F"],
            chunk_id=chunk.chunk_id,
            source_file="test",
            page_range=chunk.page_range,
            chapter=chunk.chapter_title,
            section=chunk.section_title,
            confidence=0.75
        )
    })
    
    return borderline_pairs


def test_borderline_qa():
    """Tester le Critic avec des QA borderline."""
    
    print("=" * 70)
    print("TEST: CRITIC AVEC QA BORDERLINE / CAS LIMITES")
    print("=" * 70)
    print()
    print("Ce test vÃ©rifie que le Critic produit des scores VARIÃ‰S (pas 0 ou 1)")
    print("et discrimine les cas subtils avec des scores comme 3/5, 4/5, etc.")
    print()
    
    client = Groq(api_key=api_key)
    
    # Charger un chunk
    chunker = SemanticChunker('data/pdfs/M2_cours.pdf')
    chunks = chunker.chunk_document()
    
    test_chunk = None
    for c in chunks:
        if c.semantic_type == "definition" and len(c.content) > 500:
            test_chunk = c
            break
    
    print(f"ğŸ“„ Chunk de test: {test_chunk.chunk_id}")
    print(f"ğŸ“ Contenu ({len(test_chunk.content)} chars):")
    print("-" * 50)
    print(test_chunk.content[:600])
    print("-" * 50)
    
    # CrÃ©er les QA borderline
    borderline_items = create_borderline_qa_pairs(test_chunk)
    
    # Initialiser le Critic
    critic = CriticAgent(
        llm_client=client,
        model_name="llama-3.3-70b-versatile",
        language="fr",
        temperature=0.2,
        strict_mode=True
    )
    
    print(f"\n{'='*70}")
    print(f"Ã‰VALUATION DE {len(borderline_items)} QA BORDERLINE")
    print("="*70)
    
    results = []
    score_distribution = {"0-0.3": 0, "0.3-0.5": 0, "0.5-0.7": 0, "0.7-0.9": 0, "0.9-1.0": 0}
    criteria_scores = {c: [] for c in ["anchoring", "local_answerability", "factual_accuracy", "completeness", "clarity"]}
    
    for i, item in enumerate(borderline_items, 1):
        qa = item["qa"]
        label = item["label"]
        expected = item["expected_issues"]
        
        print(f"\n{'â”€'*70}")
        print(f"TEST #{i}: {label}")
        print(f"ProblÃ¨mes attendus: {expected}")
        print(f"{'â”€'*70}")
        print(f"Q: {qa.question}")
        print(f"R: {qa.answer[:120]}..." if len(qa.answer) > 120 else f"R: {qa.answer}")
        
        evaluation = critic.evaluate(qa, test_chunk)
        results.append((item, evaluation))
        
        # Classifier le score
        score = evaluation.overall_score
        if score < 0.3:
            score_distribution["0-0.3"] += 1
        elif score < 0.5:
            score_distribution["0.3-0.5"] += 1
        elif score < 0.7:
            score_distribution["0.5-0.7"] += 1
        elif score < 0.9:
            score_distribution["0.7-0.9"] += 1
        else:
            score_distribution["0.9-1.0"] += 1
        
        # Collecter les scores par critÃ¨re
        for crit, ev in evaluation.criteria_evaluations.items():
            criteria_scores[crit].append(ev.score)
        
        # Afficher rÃ©sultat
        decision_icon = "âœ… PASS" if evaluation.decision == FinalDecision.PASS else "âŒ REJECT"
        print(f"\n{decision_icon} | Score: {evaluation.overall_score:.2f}")
        
        # Afficher critÃ¨res avec codes couleur
        passed = 0
        failed = 0
        for crit, ev in evaluation.criteria_evaluations.items():
            if ev.score >= 0.7:
                icon = "âœ“"
                passed += 1
            else:
                icon = "âœ—"
                failed += 1
            print(f"   {icon} {crit}: {ev.score:.2f}")
        
        print(f"   â†’ CritÃ¨res: {passed}/5 passÃ©s, {failed}/5 Ã©chouÃ©s")
        
        if evaluation.rejection_reasons:
            print(f"   Raisons: {evaluation.rejection_reasons[:2]}")
    
    # ================== ANALYSE DE LA VARIABILITÃ‰ ==================
    print("\n" + "=" * 70)
    print("ANALYSE DE LA VARIABILITÃ‰ DES SCORES")
    print("=" * 70)
    
    # Distribution des scores globaux
    print("\nğŸ“Š DISTRIBUTION DES SCORES GLOBAUX:")
    print("-" * 40)
    total = len(results)
    for bucket, count in score_distribution.items():
        bar = "â–ˆ" * (count * 3) if count > 0 else ""
        pct = 100 * count / total
        print(f"   {bucket}: {bar} {count} ({pct:.0f}%)")
    
    # VariÃ©tÃ© des scores par critÃ¨re
    print("\nğŸ“ˆ SCORES PAR CRITÃˆRE (min - moy - max):")
    print("-" * 40)
    for crit, scores in criteria_scores.items():
        min_s = min(scores)
        max_s = max(scores)
        avg_s = sum(scores) / len(scores)
        variance = sum((s - avg_s)**2 for s in scores) / len(scores)
        
        # Indicateur de variÃ©tÃ©
        variety = "ğŸ”´ AUCUNE" if variance < 0.01 else "ğŸŸ¡ FAIBLE" if variance < 0.05 else "ğŸŸ¢ BONNE" if variance < 0.1 else "ğŸŸ¢ EXCELLENTE"
        
        print(f"   {crit:22}: {min_s:.2f} - {avg_s:.2f} - {max_s:.2f} (var={variance:.3f}) {variety}")
    
    # Scores uniques observÃ©s
    all_scores = [e.overall_score for _, e in results]
    unique_scores = len(set(f"{s:.2f}" for s in all_scores))
    
    print(f"\nğŸ¯ SCORES UNIQUES OBSERVÃ‰S: {unique_scores}/{len(results)}")
    if unique_scores == 1:
        print("   âš ï¸  PROBLÃˆME: Tous les scores sont identiques!")
    elif unique_scores < 3:
        print("   âš ï¸  PROBLÃˆME: TrÃ¨s peu de variÃ©tÃ© dans les scores")
    elif unique_scores < 5:
        print("   ğŸŸ¡ OK: VariÃ©tÃ© modÃ©rÃ©e")
    else:
        print("   âœ… BIEN: Bonne variÃ©tÃ© de scores")
    
    # RÃ©sumÃ© Pass/Reject
    print("\n" + "-" * 70)
    print("RÃ‰SUMÃ‰ DES DÃ‰CISIONS")
    print("-" * 70)
    
    passed_count = sum(1 for _, e in results if e.decision == FinalDecision.PASS)
    rejected_count = sum(1 for _, e in results if e.decision == FinalDecision.REJECT)
    
    print(f"   âœ… PASS: {passed_count} ({100*passed_count/total:.0f}%)")
    print(f"   âŒ REJECT: {rejected_count} ({100*rejected_count/total:.0f}%)")
    
    # Tableau rÃ©capitulatif
    print("\n" + "=" * 70)
    print("TABLEAU RÃ‰CAPITULATIF")
    print("=" * 70)
    print(f"{'#':<3} {'Label':<45} {'Score':<6} {'CritÃ¨res':<10} {'DÃ©cision':<8}")
    print("-" * 70)
    
    for i, (item, evaluation) in enumerate(results, 1):
        label = item["label"][:42] + "..." if len(item["label"]) > 45 else item["label"]
        score = f"{evaluation.overall_score:.2f}"
        
        passed_criteria = sum(1 for ev in evaluation.criteria_evaluations.values() if ev.score >= 0.7)
        criteria_str = f"{passed_criteria}/5"
        
        decision = "PASS" if evaluation.decision == FinalDecision.PASS else "REJECT"
        
        print(f"{i:<3} {label:<45} {score:<6} {criteria_str:<10} {decision:<8}")
    
    # Conclusion
    print("\n" + "=" * 70)
    print("CONCLUSION")
    print("=" * 70)
    
    # CritÃ¨res de succÃ¨s du test
    has_variety = unique_scores >= 4
    has_partial_passes = any(
        0.5 <= e.overall_score < 0.9 
        for _, e in results
    )
    has_mixed_criteria = any(
        1 <= sum(1 for ev in e.criteria_evaluations.values() if ev.score >= 0.7) <= 4
        for _, e in results
    )
    
    if has_variety and has_partial_passes and has_mixed_criteria:
        print("âœ… Le Critic produit des scores VARIÃ‰S et discrimine les cas limites!")
        print("   â†’ PrÃªt pour passer Ã  l'Ã©tape suivante.")
    else:
        print("âš ï¸  PROBLÃˆMES DÃ‰TECTÃ‰S:")
        if not has_variety:
            print("   - Pas assez de variÃ©tÃ© dans les scores globaux")
        if not has_partial_passes:
            print("   - Pas de scores intermÃ©diaires (tout est 0 ou 1)")
        if not has_mixed_criteria:
            print("   - Les critÃ¨res passent tous ou Ã©chouent tous ensemble")
        print("\n   â†’ Le Critic pourrait Ãªtre trop binaire.")
    
    # Sauvegarder
    output = {
        "test_type": "borderline_qa_discrimination",
        "total_tested": len(results),
        "score_distribution": score_distribution,
        "unique_scores": unique_scores,
        "passed": passed_count,
        "rejected": rejected_count,
        "criteria_stats": {
            crit: {
                "min": min(scores),
                "max": max(scores),
                "avg": sum(scores)/len(scores),
                "variance": sum((s - sum(scores)/len(scores))**2 for s in scores) / len(scores)
            }
            for crit, scores in criteria_scores.items()
        },
        "details": [
            {
                "label": item["label"],
                "expected_issues": item["expected_issues"],
                "question": item["qa"].question,
                "answer": item["qa"].answer,
                "decision": evaluation.decision.value,
                "overall_score": evaluation.overall_score,
                "criteria_scores": {c: e.score for c, e in evaluation.criteria_evaluations.items()},
                "criteria_passed": sum(1 for e in evaluation.criteria_evaluations.values() if e.score >= 0.7)
            }
            for item, evaluation in results
        ]
    }
    
    with open("test_borderline_results.json", "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ RÃ©sultats sauvegardÃ©s: test_borderline_results.json")


if __name__ == "__main__":
    test_borderline_qa()
